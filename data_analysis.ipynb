{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Level Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary \n",
    "\n",
    "**Demographic information about the respondents**\n",
    " - Gender :\n",
    " - Age :\n",
    " - Height : \n",
    " - Weight : \n",
    "\n",
    "**Historical Information**\n",
    "- Family History iwth Overweight : \n",
    "\n",
    "**Eating Habits**\n",
    "- CALC : Alcohol consumption \n",
    "- SCC : Calories consumption \n",
    "- CH2O : Water drinking habit\n",
    "- FAVC : Caloric food consumption \n",
    "- FCVC : Vegetable Consumption\n",
    "- NCP : daily count of Main meal \n",
    "- CAEC : Food between meals \n",
    "\n",
    "**Physical Condition**\n",
    "- MTRANS : transportation used\n",
    "- TUE : Use of technological devices\n",
    "- FAF : frequency of pyhsical activities\n",
    "- SMOKE : Are you a smoker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis \n",
    "\n",
    "**Based on Demographics**\n",
    "- Are Females more likely to be obessed than Males based on eating habits and physical conditions\n",
    "- Are Males more likely to be obessed than Females based on eating habits and physical conditions\n",
    "- Are older people more likely to be obessed than younger ones\n",
    "- Does the weight and height of a person affect their likelihood to be obessed \n",
    "- Does obesity in family historical increase obesity levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
       "\n",
       "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "\n",
       "                  MTRANS           NObeyesdad  \n",
       "0  Public_Transportation        Normal_Weight  \n",
       "1  Public_Transportation        Normal_Weight  \n",
       "2  Public_Transportation        Normal_Weight  \n",
       "3                Walking   Overweight_Level_I  \n",
       "4  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import obesity data using python pandas library\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/mac/Documents/USD/Applied-AI-Group-Projects/obesity.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Male      1068\n",
      "Female    1043\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "foodBetweenMeals\n",
      "Sometimes     1765\n",
      "Frequently     242\n",
      "Always          53\n",
      "no              51\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "alcFreq\n",
      "Sometimes     1401\n",
      "no             639\n",
      "Frequently      70\n",
      "Always           1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "transp\n",
      "Public_Transportation    1580\n",
      "Automobile                457\n",
      "Walking                    56\n",
      "Motorbike                  11\n",
      "Bike                        7\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "obesityLvl\n",
      "Obesity_Type_I         351\n",
      "Obesity_Type_III       324\n",
      "Obesity_Type_II        297\n",
      "Overweight_Level_I     290\n",
      "Overweight_Level_II    290\n",
      "Normal_Weight          287\n",
      "Insufficient_Weight    272\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Categorical variables analysis\n",
    "print(df['gender'].value_counts(), \"\\n\")\n",
    "print(df['foodBetweenMeals'].value_counts(), \"\\n\")\n",
    "print(df['alcFreq'].value_counts(), \"\\n\")\n",
    "print(df['transp'].value_counts(), \"\\n\")\n",
    "print(df['obesityLvl'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                            0\n",
       "Age                               0\n",
       "Height                            0\n",
       "Weight                            0\n",
       "family_history_with_overweight    0\n",
       "FAVC                              0\n",
       "FCVC                              0\n",
       "NCP                               0\n",
       "CAEC                              0\n",
       "SMOKE                             0\n",
       "CH2O                              0\n",
       "SCC                               0\n",
       "FAF                               0\n",
       "TUE                               0\n",
       "CALC                              0\n",
       "MTRANS                            0\n",
       "NObeyesdad                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Categorical Variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling : Before applying Linear models like logistic regression, data needs to be scaled to keep all features strictly numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender']= df['Gender'].map({'Male':1, 'Female':0}).astype('int')\n",
    "df['family_history_with_overweight']= df['family_history_with_overweight'].map({'yes':1, 'no':0}).astype('int')\n",
    "df['FAVC']= df['FAVC'].map({'yes':1, 'no':0}).astype('int')\n",
    "df['CAEC']= df['CAEC'].map({'Always':3, 'Frequently':2, 'Sometimes': 1, 'no':0}).astype('int')\n",
    "df['CALC']= df['CALC'].map({'Always':3, 'Frequently':2, 'Sometimes': 1, 'no':0}).astype('int')\n",
    "df['SMOKE']= df['SMOKE'].map({'yes':1, 'no':0}).astype('int')\n",
    "df['SCC']= df['SCC'].map({'yes':1, 'no':0}).astype('int')\n",
    "df['MTRANS']= df['MTRANS'].map({'Automobile':4, 'Motorbike':3, 'Bike':2, 'Public_Transportation': 1, 'Walking':0}).astype('int')\n",
    "df['NObeyesdad']= df['NObeyesdad'].map({'Obesity_Type_III':6, 'Obesity_Type_II':5, 'Obesity_Type_I':4, 'Overweight_Level_II':3, 'Overweight_Level_I':2, 'Normal_Weight': 1, 'Insufficient_Weight':0}).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight  family_history_with_overweight  FAVC  FCVC  \\\n",
       "0       0  21.0    1.62    64.0                               1     0   2.0   \n",
       "1       0  21.0    1.52    56.0                               1     0   3.0   \n",
       "2       1  23.0    1.80    77.0                               1     0   2.0   \n",
       "3       1  27.0    1.80    87.0                               0     0   3.0   \n",
       "4       1  22.0    1.78    89.8                               0     0   2.0   \n",
       "\n",
       "   NCP  CAEC  SMOKE  CH2O  SCC  FAF  TUE  CALC  MTRANS  NObeyesdad  \n",
       "0  3.0     1      0   2.0    0  0.0  1.0     0       1           1  \n",
       "1  3.0     1      1   3.0    1  3.0  0.0     1       1           1  \n",
       "2  3.0     1      0   2.0    0  2.0  1.0     2       1           1  \n",
       "3  3.0     1      0   2.0    0  2.0  0.0     2       0           2  \n",
       "4  1.0     1      0   2.0    0  0.0  0.0     1       1           3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split target (Dependent) variable from response variables (Independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('NObeyesdad', axis=1) # response variables\n",
    "y = df['NObeyesdad'] # target vector variable y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling for Independent variables \n",
    "\n",
    "This step in data Pre Processing is applied to independent variables or features of data, to help normalize the data within a particular range of similar values. To ensure fair contribution of individual features in the obesity dataset we employ feature scaling to reduce bias towards features with larger values. Sometimes, it also helps in speeding up the calculations in an algorithm.\n",
    "\n",
    "Standard scalar was used as our dataset has a normal distribution and standardscalar is best suited for normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age','Height','Weight']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "st = StandardScaler()\n",
    "X[cols] = st.fit_transform(X[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-0.875589</td>\n",
       "      <td>-0.862558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.522124</td>\n",
       "      <td>-1.947599</td>\n",
       "      <td>-1.168077</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.206889</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>-0.366090</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.423582</td>\n",
       "      <td>1.054029</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.364507</td>\n",
       "      <td>0.839627</td>\n",
       "      <td>0.122740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender       Age    Height    Weight  family_history_with_overweight  FAVC  \\\n",
       "0       0 -0.522124 -0.875589 -0.862558                               1     0   \n",
       "1       0 -0.522124 -1.947599 -1.168077                               1     0   \n",
       "2       1 -0.206889  1.054029 -0.366090                               1     0   \n",
       "3       1  0.423582  1.054029  0.015808                               0     0   \n",
       "4       1 -0.364507  0.839627  0.122740                               0     0   \n",
       "\n",
       "   FCVC  NCP  CAEC  SMOKE  CH2O  SCC  FAF  TUE  CALC  MTRANS  \n",
       "0   2.0  3.0     1      0   2.0    0  0.0  1.0     0       1  \n",
       "1   3.0  3.0     1      1   3.0    1  3.0  0.0     1       1  \n",
       "2   2.0  3.0     1      0   2.0    0  2.0  1.0     2       1  \n",
       "3   3.0  3.0     1      0   2.0    0  2.0  0.0     2       0  \n",
       "4   2.0  1.0     1      0   2.0    0  0.0  0.0     1       1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obesity Level Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below splits the dataset into train nad test, applies an ml model to predict target variable, calculates accuracy and cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store model results\n",
    "modeldf = {}\n",
    "\n",
    "def model_val(model, X, y):\n",
    "    \"\"\"\n",
    "    this function trains and evaluates a classification model.\n",
    "\n",
    "    Parameters:\n",
    "    model : This refers to the model to be trained and evaluated.\n",
    "        sklearn estimator (e.g., LogisticRegression, SVC, etc.)\n",
    "    X : array-like, shape (n_samples, n_features) \n",
    "        dataset Independent variables /  Feature matrix.\n",
    "    y : array-like, shape (n_samples,)\n",
    "        dataset dependent/predictor variable /Target labels.\n",
    "    \"\"\"\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y) \n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute accuracy score\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # F1-Score (Weighted average) for handling class imbalance\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Cross-validate the model\n",
    "    scores = cross_val_score(model, X, y, cv=10)\n",
    "    avg_cv_score = np.mean(scores)\n",
    "    \n",
    "   # Initialize logloss variable\n",
    "    logloss = None\n",
    "\n",
    "    # Log Loss (requires predicted probabilities) - optimized by ChatGPT \n",
    "    if hasattr(model, \"predict_proba\"):  # Ensure the model supports predict_proba \n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        logloss = log_loss(y_test, y_prob)\n",
    "\n",
    "    # Print only the relevant output\n",
    "    print(f\"{model.__class__.__name__} Accuracy: {round(acc * 100, 4)}%\")\n",
    "    print(f\"{model.__class__.__name__} Avg Cross-Validation Score: {round(avg_cv_score * 100, 4)}%\")\n",
    "    print(f\"{model.__class__.__name__} F1-Score (Weighted): {round(f1 * 100, 4)}%\")\n",
    "\n",
    "    # Print log loss if available\n",
    "    if logloss is not None:\n",
    "        print(f\"{model.__class__.__name__} Log Loss: {round(logloss, 4)}\")\n",
    "    else:\n",
    "        print(f\"{model.__class__.__name__} Log Loss: N/A (Model does not support predict_proba)\")\n",
    "\n",
    "    # Store results in the dictionary\n",
    "    modeldf[type(model).__name__] = {\n",
    "        \"CV Score\": round(avg_cv_score * 100, 2),\n",
    "        \"Accuracy Score\": round(acc * 100, 2),\n",
    "        \"F1 Score\": round(f1 * 100, 2),\n",
    "        \"Log Loss\": round(logloss * 100, 2) if logloss is not None else 'N/A'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obesity Level Prediction using Logistic Regression \n",
    "\n",
    "Since our dataset target (Dependent) variable has 1-6 label represnting levels of obesity, we will use a OneVsOneClassifier (one-vs-one)logistic regression classification model as it is best suited for classification with such number of labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Define and evaluate the model\n",
    "model = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "model_val(model, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Distribution of Target Class in Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NObeyesdad\n",
       "4    0.166469\n",
       "6    0.153436\n",
       "5    0.140403\n",
       "3    0.137441\n",
       "2    0.137441\n",
       "1    0.135664\n",
       "0    0.129147\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/len(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NObeyesdad\n",
       "4    0.165485\n",
       "6    0.153664\n",
       "5    0.141844\n",
       "1    0.137116\n",
       "3    0.137116\n",
       "2    0.137116\n",
       "0    0.127660\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obesity Level Prediction using GradientBoosting Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting classifier is a Strong learner that combines weak classifiers for high accuracy and handles complex relationships well. Gradient boosting was selected as one of the algoritms to use on this dataset because the clasissifcation of obesisty levels is focused on eating habits and physical condition explanatory variables which are factors GBC captures better than linear models and learns effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier Accuracy: 94.5626%\n",
      "GradientBoostingClassifier Avg Cross-Validation Score: 96.0248%\n",
      "GradientBoostingClassifier F1-Score (Weighted): 94.5546%\n",
      "GradientBoostingClassifier Log Loss: 0.2026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "model_val(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Obesity Level Prediction using Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Accuracy: 91.7258%\n",
      "DecisionTreeClassifier Avg Cross-Validation Score: 92.8999%\n",
      "DecisionTreeClassifier F1-Score (Weighted): 91.7657%\n",
      "DecisionTreeClassifier Log Loss: 2.9823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model_val(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obesity Level Prediction using Random Forest Classifier\n",
    "This model is good at reducing overfitting, provides feature importance, and handles non-linear relationships. For the obesity dataset, there are non-linear relationships like ....... Random Forest was thus selected to help manage this while predicting the levels of obesity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Accuracy: 94.3262%\n",
      "RandomForestClassifier Avg Cross-Validation Score: 94.5614%\n",
      "RandomForestClassifier F1-Score (Weighted): 94.3827%\n",
      "RandomForestClassifier Log Loss: 0.2582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model_val(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Obesity Level Prediction using XGB Classifier\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is also another excellent choice  model for obesity level classification (multi-class classification with target values 1-6). It builds on the concepts of Gradient Boosting but optimizes speed, performance, and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier Accuracy: 94.7991%\n",
      "XGBClassifier Avg Cross-Validation Score: 96.7352%\n",
      "XGBClassifier F1-Score (Weighted): 94.7856%\n",
      "XGBClassifier Log Loss: 0.1615\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model_val(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Obesity Level Prediction using Support Vector Machines\n",
    "\n",
    "Since the obesity dataset is relatively small, the SVM algorithm was employed as it works well for small to medium-sized datasets by using the kernel trick for complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 90.3073%\n",
      "SVC Avg Cross-Validation Score: 90.9128%\n",
      "SVC F1-Score (Weighted): 90.3297%\n",
      "SVC Log Loss: N/A (Model does not support predict_proba)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model_val(model,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model  CV Score  Accuracy  F1 Score Log Loss\n",
      "0          OneVsOneClassifier     94.94     94.09     94.02      N/A\n",
      "1  GradientBoostingClassifier     96.02     94.56     94.55    20.26\n",
      "2      DecisionTreeClassifier     92.90     91.73     91.77   298.23\n",
      "3      RandomForestClassifier     94.56     94.33     94.38    25.82\n",
      "4               XGBClassifier     96.74     94.80     94.79    16.15\n",
      "5                         SVC     90.91     90.31     90.33      N/A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert modeldf to a Pandas DataFrame\n",
    "df_results = pd.DataFrame.from_dict(modeldf, orient='index').reset_index()\n",
    "df_results.columns = [\"Model\", \"CV Score\", \"Accuracy\", \"F1 Score\", \"Log Loss\"]\n",
    "\n",
    "# Display the results\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>96.74</td>\n",
       "      <td>94.80</td>\n",
       "      <td>94.79</td>\n",
       "      <td>16.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>96.02</td>\n",
       "      <td>94.56</td>\n",
       "      <td>94.55</td>\n",
       "      <td>20.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>94.56</td>\n",
       "      <td>94.33</td>\n",
       "      <td>94.38</td>\n",
       "      <td>25.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneVsOneClassifier</td>\n",
       "      <td>94.94</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.02</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>92.90</td>\n",
       "      <td>91.73</td>\n",
       "      <td>91.77</td>\n",
       "      <td>298.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>90.91</td>\n",
       "      <td>90.31</td>\n",
       "      <td>90.33</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  CV Score  Accuracy  F1 Score Log Loss\n",
       "0               XGBClassifier     96.74     94.80     94.79    16.15\n",
       "1  GradientBoostingClassifier     96.02     94.56     94.55    20.26\n",
       "2      RandomForestClassifier     94.56     94.33     94.38    25.82\n",
       "3          OneVsOneClassifier     94.94     94.09     94.02      N/A\n",
       "4      DecisionTreeClassifier     92.90     91.73     91.77   298.23\n",
       "5                         SVC     90.91     90.31     90.33      N/A"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by 'Accuracy' and then 'CV Score', both in descending order\n",
    "df_results.sort_values(by=['Accuracy', 'CV Score'], ascending=[False, False]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameter Tuning - Using RandomizedSearchCV\n",
    "\n",
    "The obesity dataset has 16 features as explanatory dependent variables as such, RandomizedSearchCV is an efficient method for tuning obesity dataset hyperparameters as there are many parameters to explore. The approach ensures that we do not have to search the entire parameter space exhaustively, but still manage to find optimal or near-optimal hyperparameters within the given number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "\n",
    "rf_grid = {'n_estimators': np.arange(10,1000,10),\n",
    "'max_features':['auto', 'sqrt'],\n",
    "'max_depth': [None,3,5,10,20,30],\n",
    "'min_samples_split':[2,5,20,50,100],\n",
    "'min_samples_leaf':[1,2,5,10]\n",
    "}\n",
    "\n",
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(), \n",
    "                                param_distributions=rf_grid,\n",
    "                                n_iter=20,\n",
    "                                cv=10,\n",
    "                                verbose=True)\n",
    "\n",
    "rs_rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9470423857641063"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest had no significant change after tuning the hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for XGBClassifier\n",
    "xgb_grid = {\n",
    "    'n_estimators': np.arange(50, 1001, 50),  # Number of boosting rounds (trees)\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],  # Step size shrinking\n",
    "    'max_depth': [3, 5, 7, 10, 12],  # Depth of trees\n",
    "    'min_child_weight': [1, 3, 5, 7],  # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'subsample': [0.5, 0.7, 0.8, 1.0],  # Fraction of samples used for each tree\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 1.0],  # Fraction of features used for each tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],  # Minimum loss reduction required to make a further partition\n",
    "    'scale_pos_weight': [1, 2, 3]  # Balance of positive and negative weights (useful for imbalanced classes)\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for XGBClassifier\n",
    "rs_xgb = RandomizedSearchCV(XGBClassifier(),\n",
    "                            param_distributions=xgb_grid,\n",
    "                            n_iter=20,  # Number of iterations for randomized search\n",
    "                            cv=10,  # 10-fold cross-validation\n",
    "                            verbose=True,  # Print progress\n",
    "                            n_jobs=-1,  # Use all available processors\n",
    "                            random_state=42)  # Ensure reproducibility\n",
    "\n",
    "# Fit the model\n",
    "rs_xgb.fit(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Best Parameters: {'subsample': 0.7, 'scale_pos_weight': 1, 'n_estimators': \"\n",
      " \"400, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.2, 'gamma': \"\n",
      " \"0.1, 'colsample_bytree': 1.0}\")\n",
      "\n",
      "Best Cross-validation Score: 0.9659371367253866\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Display the best parameters and score\n",
    "pprint(f\"Best Parameters: {rs_xgb.best_params_}\")\n",
    "print(f\"\\nBest Cross-validation Score: {rs_xgb.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for GradientBoostingClassifier\n",
    "gbc_grid = {\n",
    "    'n_estimators': np.arange(50, 1001, 50),  # Number of boosting rounds (trees)\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],  # Step size shrinking\n",
    "    'max_depth': [3, 5, 7, 10, 12],  # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10, 20, 50],  # Minimum samples to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 5, 10],  # Minimum samples required at a leaf node\n",
    "    'subsample': [0.5, 0.7, 0.8, 1.0],  # Fraction of samples used for each tree\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at each split\n",
    "    'loss': ['deviance', 'exponential']  # Loss function: 'deviance' for logistic, 'exponential' for AdaBoost-like\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for GradientBoostingClassifier\n",
    "rs_gbc = RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                            param_distributions=gbc_grid,\n",
    "                            n_iter=20,  # Number of iterations for randomized search\n",
    "                            cv=10,  # 10-fold cross-validation\n",
    "                            verbose=True,  # Print progress\n",
    "                            n_jobs=-1,  # Use all available processors\n",
    "                            random_state=42)  # Ensure reproducibility\n",
    "\n",
    "# Fit the model\n",
    "rs_gbc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best parameters and score\n",
    "print(f\"Best Parameters: {rs_gbc.best_params_}\")\n",
    "print(f\"Best Cross-validation Score: {rs_gbc.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "- Sklearn one-vs-one Logistice regression classification algoritm : https://scikit-learn.org/stable/modules/multiclass.html#ovo-classification\n",
    "- Feature Scaling : https://www.geeksforgeeks.org/python-how-and-where-to-apply-feature-scaling/?ref=header_outind\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
